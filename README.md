# React GLSL Shader Image Editor

[**Live Demo**](https://microsoftdesigner.vercel.app/)

![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&logo=react&logoColor=%2361DAFB)
![WebGL](https://img.shields.io/badge/WebGL-990000?style=for-the-badge&logo=webgl&logoColor=white)
![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E)
![CSS3](https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white)

An advanced, web-based image editor built with React that combines standard CSS effects with a powerful, GPU-accelerated WebGL rendering pipeline for applying custom GLSL fragment shaders. The standout feature is the ability to generate and apply unique shaders on-the-fly using AI, offering limitless creative possibilities.

---

## Key Features

* **üñºÔ∏è Image Upload & Viewer:** Simple drag-and-drop or file-select interface to load images.
* **üé® Dual-Mode Effects System:**
    * **Live CSS Effects:** Non-destructive sliders for real-time adjustments of Brightness, Contrast, Saturation, and Hue.
    * **Destructive WebGL Effects:** GPU-accelerated application of advanced GLSL shaders for high-performance image manipulation.
* **ü§ñ AI-Powered Shader Generation:**
    * Leverages a generative AI model to create complex GLSL fragment shaders from plain text prompts.
    * Allows users to describe an effect (e.g., "a glitchy, old TV screen effect") and apply the generated shader directly to the image.
* **‚è™ Global Undo/Reset:** A robust, multi-level undo stack for all destructive operations (both CSS and WebGL filters), and a one-click reset to revert to the original image.
* **üîç Zoom & Pan:** Intuitive floating controls for zooming and panning, allowing for precise, pixel-level inspection.
* **üß© Extensible Shader Architecture:** The WebGL effects system is fully data-driven. New shaders can be added simply by defining them in a central `shaders.js` file, with no changes needed to the core application logic.

## Technology Stack

* **React:** For building the component-based user interface.
* **WebGL:** Used for high-performance, GPU-accelerated image processing. The application features a custom renderer class to compile and run GLSL shaders.
* **GLSL (OpenGL Shading Language):** The language used to write the fragment shaders that create the visual effects.
* **JavaScript (ES6+):** The core language of the application.
* **CSS3:** For modern styling and layout, including the responsive sidebar and floating controls.

## Architectural Highlights

This project was designed to be both powerful and easy to maintain.

1.  **Data-Driven Shader System:** All WebGL effects are defined in `src/components/babylon/shaders.js`. This file acts as a "shader library," allowing developers to add, remove, or edit complex effects by simply modifying a single file. The UI and renderer adapt automatically.

2.  **Generic WebGL Renderer:** The `GLSLRenderer.js` class is completely agnostic. It accepts any valid fragment shader source code and a list of parameters (uniforms), then compiles and executes it. This makes the system highly flexible and capable of handling diverse effects, including those generated by AI.

3.  **Hybrid Editing Model:** The editor intelligently combines two editing paradigms:
    * **Non-Destructive Sliders:** Effects like brightness and contrast are applied via CSS filters for a real-time, lag-free experience without altering the underlying image data.
    * **Destructive Filters:** More complex operations (like Posterize, Pixalate, or AI-generated effects) are "baked" into the image data. This creates a new state in the undo history, allowing for a layered, step-by-step workflow.

4.  **Centralized State Management:** The root `App.js` component acts as the single source of truth, managing the original image, the processed image, the global undo history, and the state of all applied effects. This simplifies data flow and prevents state-related bugs.

## How It Works

### Applying a Pre-defined WebGL Shader

1.  The user uploads an image.
2.  The `BabylonEffects` component reads the available shaders from `shaders.js` and renders a button for each.
3.  The user clicks a button (e.g., "Posterize").
4.  `BabylonEffects` passes the current image, the shader's GLSL source code, and its default parameters to the `GLSLRenderer`.
5.  `GLSLRenderer` creates a WebGL context, compiles the shader, sets the uniforms, and draws the image to an offscreen canvas.
6.  The canvas content is exported as a new `dataURL`.
7.  `App.js` receives this new image data, pushes the *previous* image state to the undo stack, and updates the main view to display the newly rendered image.

### Applying an AI-Generated Shader

1.  The user opens the AI Shader Generation panel.
2.  They type a prompt, such as "a watery, shimmering reflection."
3.  The application sends this prompt to a generative AI API.
4.  The AI returns a complete GLSL fragment shader as a string.
5.  The flow then follows steps 4-7 from above, using the AI-generated shader source code instead of one from the local library.

## Project Structure